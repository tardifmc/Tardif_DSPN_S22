{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2W919d2ZXp7"
   },
   "source": [
    "# Homework 7: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4nOzVhyZXqK"
   },
   "source": [
    "This homework assignment is designed to give you practice with classification models. We'll try to predict which words are more likely to be responded to correctly during a lexical decision task, based on their length and frequency.\n",
    "\n",
    "We will be using data from the English Lexicon Project again. However, this time we will use response correctness as our dependent variable. Load **LexicalData_withIncorrect.csv**, which includes incorrect trials as well as correct ones, and also **Items.csv**. Both can be found in the *Homework/lexDat* folder in the class GitHub repository. \n",
    "\n",
    "This data is a subset of the [English Lexicon Project database](https://elexicon.wustl.edu/). It provides response correctness and reaction times (in milliseconds) of many subjects as they are presented with letter strings and asked to decide, as quickly and as accurately as possible, whether the letter string is a word or not. The **Items.csv** provides characteristics of the words used, namely frequency (how common is this word?) and length (how many letters?). \n",
    "\n",
    "*Data courtesy of Balota, D.A., Yap, M.J., Cortese, M.J., Hutchison, K.A., Kessler, B., Loftis, B., Neely, J.H., Nelson, D.L., Simpson, G.B., & Treiman, R. (2007). The English Lexicon Project. Behavior Research Methods, 39, 445-459.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DsyBTB6ZXqN"
   },
   "source": [
    "---\n",
    "## 1. Loading and formatting the data (1 point)\n",
    "\n",
    "Load in data from the **LexicalData_withIncorrect.csv** and **Items.csv** files. Use `left_join` to add word characteristics `Length` and `Log_Freq_Hal` from **Items** to the **LexicalData**, and use `drop_na()` to get rid of any observations with missing values. Then use `head()` to look at the first few rows of the data. \n",
    "\n",
    "*Note: We're just working with `Correct` in this homework, so no need to worry about reformatting reaction times.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "executionInfo": {
     "elapsed": 7413,
     "status": "ok",
     "timestamp": 1617034976794,
     "user": {
      "displayName": "Patience Stevens",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi-_9ZqhIFhAv1oMehJNvNuIKSTyrFQHzjxQKhx=s64",
      "userId": "01994571539255174942"
     },
     "user_tz": 240
    },
    "id": "UnBVazYfZXqP",
    "outputId": "0fedfa64-26db-49cc-da34-02cf74bf29d4"
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in select(items, Word, Length, Log_Freq_HAL): unused arguments (Word, Length, Log_Freq_HAL)\n",
     "output_type": "error",
     "traceback": [
      "Error in select(items, Word, Length, Log_Freq_HAL): unused arguments (Word, Length, Log_Freq_HAL)\nTraceback:\n",
      "1. LD %>% left_join(select(items, Word, Length, Log_Freq_HAL), by = c(D_Word = \"Word\"))",
      "2. left_join(., select(items, Word, Length, Log_Freq_HAL), by = c(D_Word = \"Word\"))",
      "3. left_join.data.frame(., select(items, Word, Length, Log_Freq_HAL), \n .     by = c(D_Word = \"Word\"))",
      "4. auto_copy(x, y, copy = copy)",
      "5. same_src(x, y)",
      "6. same_src.data.frame(x, y)",
      "7. is.data.frame(y)"
     ]
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "\n",
    "setwd(\"C:/Users/MCT40/OneDrive - University of Pittsburgh/Classes/Spring2022/CMU_STATS/HOMEWORK\")\n",
    "LD <- read.csv(\"lexDat/LexicalData_withIncorrect.csv\")\n",
    "items <- read.csv(\"lexDat/items.csv\")\n",
    "\n",
    "#names(LD)[names(LD) == \"D_Word\"] <- \"Word\" =\n",
    "#LD <- left_join(LD, items, by='Word') #adding together all of the variables to make the final question of the homework easier\n",
    "\n",
    "LD %>% \n",
    "  left_join(\n",
    "    select(items, Word, Length, Log_Freq_HAL),\n",
    "    by = c(\"D_Word\"=\"Word\")\n",
    "  ) -> LD2\n",
    "\n",
    "LD2 %>% drop_na() -> LD3 #remove NAs save to LD2\n",
    "any(LD3 == \"n/a\")\n",
    "\n",
    "head(LD3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BeK0H64WlOBM"
   },
   "source": [
    "---\n",
    "## 2. Visualizing the data (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dP_6o9rpmThw"
   },
   "source": [
    "First, we'll try to visualize whether trials that are responded to correctly versus incorrectly differ from each other in terms of word length and log frequency. The code is included below, so that this homework doesn't get too cumbersome. All you have to do is **change the name of the data set**, **run the code**, and **write some observations about the output**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "executionInfo": {
     "elapsed": 4369,
     "status": "ok",
     "timestamp": 1616456271097,
     "user": {
      "displayName": "Patience Stevens",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi-_9ZqhIFhAv1oMehJNvNuIKSTyrFQHzjxQKhx=s64",
      "userId": "01994571539255174942"
     },
     "user_tz": 240
    },
    "id": "PIPheP5ipgKg",
    "outputId": "e6d7b9a1-00fd-4358-ac36-8d802a725541"
   },
   "outputs": [],
   "source": [
    "#install.packages(\"ggplot2\")\n",
    "library(ggplot2)\n",
    "\n",
    "LD3$Correct <- as.factor(LD3$Correct) # so that R knows that Correct is categorical, not numeric. \n",
    "\n",
    "# plot the Correct / Incorrect clusters\n",
    "ggplot(LD3,aes(x=round(Log_Freq_HAL,1),y=Length,col=Correct)) + \n",
    "geom_point(position=\"jitter\",alpha=0.5) + theme_light() \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8W0y8eRxTa6Z"
   },
   "source": [
    "What do you observe about the \"Correct\" and \"Incorrect\" clusters? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWxi8O6voooe"
   },
   "source": [
    "> Shorter words and those with lower Log_Freq_Hal values tend to be more often incorrect than those with higher values in those variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3b3_KsHk-xD"
   },
   "source": [
    "---\n",
    "## 3. Logistic Regression: Fitting the model (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlahTNHxrJaR"
   },
   "source": [
    "Fit a logistic regression model to the data using `Length`, `Log_Freq_HAL`, and their interaction to predict `Correct`. Use `glm()` to fit the model, and look at its output using `summary()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "executionInfo": {
     "elapsed": 759,
     "status": "ok",
     "timestamp": 1617034981292,
     "user": {
      "displayName": "Patience Stevens",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi-_9ZqhIFhAv1oMehJNvNuIKSTyrFQHzjxQKhx=s64",
      "userId": "01994571539255174942"
     },
     "user_tz": 240
    },
    "id": "AidH_KidrX9L",
    "outputId": "ed096fe4-8a0e-47b6-f3ff-d742010edd7b"
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "Log_reg <- glm(Correct ~ Length*Log_Freq_HAL, data= LD3, family = binomial)\n",
    "summary(Log_reg)\n",
    "\n",
    "#Because GITHUB womp womp: \n",
    "\n",
    "# Call:\n",
    "#   glm(formula = Correct ~ Length * Log_Freq_HAL, family = binomial, \n",
    "#       data = LD3)\n",
    "# \n",
    "# Deviance Residuals: \n",
    "#   Min       1Q   Median       3Q      Max  \n",
    "# -3.0494   0.3178   0.4182   0.5208   1.3225  \n",
    "# \n",
    "# Coefficients:\n",
    "#   Estimate Std. Error z value Pr(>|z|)    \n",
    "# (Intercept)         -0.939996   0.115623  -8.130 4.30e-16 ***\n",
    "#   Length               0.151266   0.012789  11.828  < 2e-16 ***\n",
    "#   Log_Freq_HAL         0.394772   0.018762  21.041  < 2e-16 ***\n",
    "#   Length:Log_Freq_HAL -0.010558   0.002202  -4.795 1.63e-06 ***\n",
    "#   ---\n",
    "#   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
    "# \n",
    "# (Dispersion parameter for binomial family taken to be 1)\n",
    "# \n",
    "# Null deviance: 49809  on 70588  degrees of freedom\n",
    "# Residual deviance: 46563  on 70585  degrees of freedom\n",
    "# (4280 observations deleted due to missingness)\n",
    "# AIC: 46571\n",
    "# \n",
    "# Number of Fisher Scoring iterations: 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9AC8nTnYtzAb"
   },
   "source": [
    "What can you conclude from this output? (a brief gist is fine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MLyXXTIuACv"
   },
   "source": [
    "> The intercept of the mode being significant represents the mean oh the correct response (which isn't sensical) when the log odds and length of the word are 0, which isn't applicable or interesting.\n",
    "\n",
    "> The main effect of length indicates that as length increases so to does the log odds of number of correct responses determining whether or not it was a real word.\n",
    "\n",
    ">The main effect of Log_Freq_HAL  indicates that as that variable increases so too do the log odds of number of correct responses determining whether or not it was a real word.\n",
    "\n",
    "> The interaction between the two terms indicates that as one of the variables increases the influence of the other variable decreases. Such that one predictor variable has a different influences on the outcome variable depending on the behaviour of the second predictor variable (Length and Log_Freq_HAL).\n",
    "\n",
    "> Because the contrasts were not coded we cannot say much more about these effects based on the estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCnLulvxA2fM"
   },
   "source": [
    "---\n",
    "## 4. Interpreting predictions from the model (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCy9W_Mou4zT"
   },
   "source": [
    "Finally, look at how well this logistic regression model does at predicting correctness. Use `predict()` and a threshold of 0.5 to generate predicted `Correct` values for each trial, then output a confusion matrix and overall accuracy for these predictions.\n",
    "\n",
    "*Hint: see the Classifiers tutorial.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "executionInfo": {
     "elapsed": 402,
     "status": "ok",
     "timestamp": 1617034997434,
     "user": {
      "displayName": "Patience Stevens",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi-_9ZqhIFhAv1oMehJNvNuIKSTyrFQHzjxQKhx=s64",
      "userId": "01994571539255174942"
     },
     "user_tz": 240
    },
    "id": "nZQ2_WzixTJH",
    "outputId": "f81245ff-330c-48a7-a9a8-410622ea5ef6"
   },
   "outputs": [],
   "source": [
    "threshold = 0.50 #assing threshold per instructions\n",
    "\n",
    "#How well the model captures the data\n",
    "LD_predict = data.frame(predict(Log_reg, type = \"response\"))\n",
    "\n",
    "## Rename the predicted values generated above to \"predicted_prob\" for ease of interpretability\n",
    "colnames(LD_predict) = c('predicted_prob')\n",
    "head(LD_predict)\n",
    "\n",
    "# Make a list of \"Incorrect\" responses (coded as 0)\n",
    "num_obs = nrow(LD3)\n",
    "LD_predict$predicted_binary=rep(0,num_obs)\n",
    "LD_predict$predicted_binary[LD_predict$predicted_prob>threshold]= 1\n",
    "\n",
    "# Look at the prediction accuracy in form of confusion matrix table\n",
    "LD_conf = data.frame(LD_predict$predicted_binary, LD3$Correct)\n",
    "colnames(LD_conf) = c('predicted', 'actual')\n",
    "table(LD_conf)\n",
    "\n",
    "## Abbreviated summary: \n",
    "## 13 predicted 0 actual 0 (true neg)\n",
    "## 44 predicted 0 actual 1 (false neg)\n",
    "## 7966 predicted 1 actual 0 (fale pos)\n",
    "## 62566 predicted 1 actual 1 (true pos)\n",
    "\n",
    "## Calculate the general accuracy of the model's predictions: \n",
    "print(paste(\"Accuracy:\",mean(LD_conf$predicted == LD_conf$actual)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-D1Kk4Wz6eA"
   },
   "source": [
    "Did the model do well at predicting lexical decision correctness? Why or why not? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHZnDFzV0K7K"
   },
   "source": [
    "> The model is doing quite well at predicting the data because the accuracy is approximately 89%. I think anything above 90% is great, so 89% is pretty good! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_xE_hjFDMe-"
   },
   "source": [
    "## 5. QDA (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzvQBhcbD995"
   },
   "source": [
    "Load in the `MASS` library and fit a QDA model to the data set. The predictors are still `Length`, `Log_Freq_HAL`, and their interaction, just like the logistic regression model you just ran, and the dependent variable is still `Correct`. \n",
    "\n",
    "*Hint: see the Classifiers tutorial.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "v5unJLgdERP_"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$prior</dt>\n",
       "\t\t<dd><style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>0</dt><dd>0.113034608791738</dd><dt>1</dt><dd>0.886965391208262</dd></dl>\n",
       "</dd>\n",
       "\t<dt>$counts</dt>\n",
       "\t\t<dd><style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>0</dt><dd>7979</dd><dt>1</dt><dd>62610</dd></dl>\n",
       "</dd>\n",
       "\t<dt>$means</dt>\n",
       "\t\t<dd><table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 3 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Length</th><th scope=col>Log_Freq_HAL</th><th scope=col>Length:Log_Freq_HAL</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>0</th><td>8.047124</td><td>4.932123</td><td>37.95260</td></tr>\n",
       "\t<tr><th scope=row>1</th><td>7.979971</td><td>6.444849</td><td>49.34219</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</dd>\n",
       "\t<dt>$scaling</dt>\n",
       "\t\t<dd><style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>-0.407515605393477</li><li>0</li><li>0</li><li>0.142592121064648</li><li>0.494311330395269</li><li>0</li><li>-0.893293218673088</li><li>-1.44963033066694</li><li>0.179044949085299</li><li>0.407536755659394</li><li>0</li><li>0</li><li>0.159655155412943</li><li>0.460482663890866</li><li>0</li><li>1.05310956232319</li><li>1.29145532948144</li><li>-0.163630582483775</li></ol>\n",
       "</dd>\n",
       "\t<dt>$ldet</dt>\n",
       "\t\t<dd><style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>6.64476836175236</li><li>6.96649632097426</li></ol>\n",
       "</dd>\n",
       "\t<dt>$lev</dt>\n",
       "\t\t<dd><style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'0'</li><li>'1'</li></ol>\n",
       "</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$prior] \\begin{description*}\n",
       "\\item[0] 0.113034608791738\n",
       "\\item[1] 0.886965391208262\n",
       "\\end{description*}\n",
       "\n",
       "\\item[\\$counts] \\begin{description*}\n",
       "\\item[0] 7979\n",
       "\\item[1] 62610\n",
       "\\end{description*}\n",
       "\n",
       "\\item[\\$means] A matrix: 2 × 3 of type dbl\n",
       "\\begin{tabular}{r|lll}\n",
       "  & Length & Log\\_Freq\\_HAL & Length:Log\\_Freq\\_HAL\\\\\n",
       "\\hline\n",
       "\t0 & 8.047124 & 4.932123 & 37.95260\\\\\n",
       "\t1 & 7.979971 & 6.444849 & 49.34219\\\\\n",
       "\\end{tabular}\n",
       "\n",
       "\\item[\\$scaling] \\begin{enumerate*}\n",
       "\\item -0.407515605393477\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0.142592121064648\n",
       "\\item 0.494311330395269\n",
       "\\item 0\n",
       "\\item -0.893293218673088\n",
       "\\item -1.44963033066694\n",
       "\\item 0.179044949085299\n",
       "\\item 0.407536755659394\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0.159655155412943\n",
       "\\item 0.460482663890866\n",
       "\\item 0\n",
       "\\item 1.05310956232319\n",
       "\\item 1.29145532948144\n",
       "\\item -0.163630582483775\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item[\\$ldet] \\begin{enumerate*}\n",
       "\\item 6.64476836175236\n",
       "\\item 6.96649632097426\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item[\\$lev] \\begin{enumerate*}\n",
       "\\item '0'\n",
       "\\item '1'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$prior\n",
       ":   0\n",
       ":   0.1130346087917381\n",
       ":   0.886965391208262\n",
       "\n",
       "\n",
       "$counts\n",
       ":   0\n",
       ":   79791\n",
       ":   62610\n",
       "\n",
       "\n",
       "$means\n",
       ":   \n",
       "A matrix: 2 × 3 of type dbl\n",
       "\n",
       "| <!--/--> | Length | Log_Freq_HAL | Length:Log_Freq_HAL |\n",
       "|---|---|---|---|\n",
       "| 0 | 8.047124 | 4.932123 | 37.95260 |\n",
       "| 1 | 7.979971 | 6.444849 | 49.34219 |\n",
       "\n",
       "\n",
       "$scaling\n",
       ":   1. -0.407515605393477\n",
       "2. 0\n",
       "3. 0\n",
       "4. 0.142592121064648\n",
       "5. 0.494311330395269\n",
       "6. 0\n",
       "7. -0.893293218673088\n",
       "8. -1.44963033066694\n",
       "9. 0.179044949085299\n",
       "10. 0.407536755659394\n",
       "11. 0\n",
       "12. 0\n",
       "13. 0.159655155412943\n",
       "14. 0.460482663890866\n",
       "15. 0\n",
       "16. 1.05310956232319\n",
       "17. 1.29145532948144\n",
       "18. -0.163630582483775\n",
       "\n",
       "\n",
       "\n",
       "$ldet\n",
       ":   1. 6.64476836175236\n",
       "2. 6.96649632097426\n",
       "\n",
       "\n",
       "\n",
       "$lev\n",
       ":   1. '0'\n",
       "2. '1'\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$prior\n",
       "        0         1 \n",
       "0.1130346 0.8869654 \n",
       "\n",
       "$counts\n",
       "    0     1 \n",
       " 7979 62610 \n",
       "\n",
       "$means\n",
       "    Length Log_Freq_HAL Length:Log_Freq_HAL\n",
       "0 8.047124     4.932123            37.95260\n",
       "1 7.979971     6.444849            49.34219\n",
       "\n",
       "$scaling\n",
       ", , 0\n",
       "\n",
       "                             1         2          3\n",
       "Length              -0.4075156 0.1425921 -0.8932932\n",
       "Log_Freq_HAL         0.0000000 0.4943113 -1.4496303\n",
       "Length:Log_Freq_HAL  0.0000000 0.0000000  0.1790449\n",
       "\n",
       ", , 1\n",
       "\n",
       "                            1         2          3\n",
       "Length              0.4075368 0.1596552  1.0531096\n",
       "Log_Freq_HAL        0.0000000 0.4604827  1.2914553\n",
       "Length:Log_Freq_HAL 0.0000000 0.0000000 -0.1636306\n",
       "\n",
       "\n",
       "$ldet\n",
       "[1] 6.644768 6.966496\n",
       "\n",
       "$lev\n",
       "[1] \"0\" \"1\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>class</th><th scope=col>posterior.0</th><th scope=col>posterior.1</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>0.02842981</td><td>0.9715702</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>1</td><td>0.15567716</td><td>0.8443228</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>1</td><td>0.05352231</td><td>0.9464777</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>1</td><td>0.25641008</td><td>0.7435899</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>1</td><td>0.31449666</td><td>0.6855033</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>1</td><td>0.14651538</td><td>0.8534846</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 3\n",
       "\\begin{tabular}{r|lll}\n",
       "  & class & posterior.0 & posterior.1\\\\\n",
       "  & <fct> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & 0.02842981 & 0.9715702\\\\\n",
       "\t2 & 1 & 0.15567716 & 0.8443228\\\\\n",
       "\t3 & 1 & 0.05352231 & 0.9464777\\\\\n",
       "\t4 & 1 & 0.25641008 & 0.7435899\\\\\n",
       "\t5 & 1 & 0.31449666 & 0.6855033\\\\\n",
       "\t6 & 1 & 0.14651538 & 0.8534846\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 3\n",
       "\n",
       "| <!--/--> | class &lt;fct&gt; | posterior.0 &lt;dbl&gt; | posterior.1 &lt;dbl&gt; |\n",
       "|---|---|---|---|\n",
       "| 1 | 1 | 0.02842981 | 0.9715702 |\n",
       "| 2 | 1 | 0.15567716 | 0.8443228 |\n",
       "| 3 | 1 | 0.05352231 | 0.9464777 |\n",
       "| 4 | 1 | 0.25641008 | 0.7435899 |\n",
       "| 5 | 1 | 0.31449666 | 0.6855033 |\n",
       "| 6 | 1 | 0.14651538 | 0.8534846 |\n",
       "\n"
      ],
      "text/plain": [
       "  class posterior.0 posterior.1\n",
       "1 1     0.02842981  0.9715702  \n",
       "2 1     0.15567716  0.8443228  \n",
       "3 1     0.05352231  0.9464777  \n",
       "4 1     0.25641008  0.7435899  \n",
       "5 1     0.31449666  0.6855033  \n",
       "6 1     0.14651538  0.8534846  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load in MASS library\n",
    "library(MASS)\n",
    "\n",
    "# Fit QDA model on data set (no test train split here)\n",
    "LD_qda = qda(Correct ~ Length*Log_Freq_HAL, data=LD3)\n",
    "head(LD_qda)\n",
    "     \n",
    "     \n",
    "# Create a data frame containing posterior probabilities of 0 and 1 for each observation\n",
    "qda_predict = data.frame(predict(LD_qda, type = \"response\"))\n",
    "head(qda_predict)\n",
    "     \n",
    "#Use threshold to determine outcome (correct/incorrect)\n",
    "qda_predict %>%\n",
    "       mutate(predicted_binary = if_else(posterior.1 >= threshold, 1, 0)) -> qda_predict_bin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YceNR0uSEquX"
   },
   "source": [
    "Now look at how well the predicted `Correct` values compare with actual `Correct` values for the whole data set. Output a confusion matrix and overall prediction accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "executionInfo": {
     "elapsed": 460,
     "status": "ok",
     "timestamp": 1616455028335,
     "user": {
      "displayName": "Patience Stevens",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi-_9ZqhIFhAv1oMehJNvNuIKSTyrFQHzjxQKhx=s64",
      "userId": "01994571539255174942"
     },
     "user_tz": 240
    },
    "id": "tvhhrDWRF2hJ",
    "outputId": "7ed64e88-6320-40b2-e900-a5d07d994635"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         actual\n",
       "predicted     0     1\n",
       "        0   455  1647\n",
       "        1  7524 60963"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Accuracy: 0.870078907478502\"\n"
     ]
    }
   ],
   "source": [
    "     conf2 = data.frame(qda_predict_bin$predicted_binary, LD3$Correct)\n",
    "     colnames(conf2) = c('predicted', 'actual')\n",
    "     table(conf2)\n",
    "     \n",
    "#print accuracy      \n",
    "     print(paste(\"Accuracy:\",mean(conf2$predicted == conf2$actual)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "leurrTYKHBe_"
   },
   "source": [
    "How does QDA prediction performance differ from that of logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3BRrwUhHV1J"
   },
   "source": [
    "> They were *slightly* worse, but very very similar (87% here and 89% accuracy for the logisitic regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4MPECMmZXqe"
   },
   "source": [
    "**DUE:** 5pm EST, March 25, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9GUofXN4BVy"
   },
   "source": [
    "**IMPORTANT** Did you collaborate with anyone on this assignment? If so, list their names here. \n",
    "> Emily Goldberg, and her fascinating taste in marshmallow, matcha, cinnamon candle scents"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Homework7_solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
